{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8660cf-61ea-490e-8fde-dc5ae75dd963",
   "metadata": {},
   "source": [
    "### Netflix ELT Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccee51-6a95-47cb-90d9-10fc7f1ee41d",
   "metadata": {},
   "source": [
    "### ETL stands for \"Extract, Load, Transform\"\n",
    "\n",
    "#### Extract\n",
    "\n",
    "The extract phase is the first step in the ELT process. In this phase, data is collected from various sources. These sources could be databases, CRM systems, social media platforms, or any other place where data is stored. The extracted data is often raw and unstructured and may come in various formats such as text, images, audio, or video.\n",
    "\n",
    "#### Load\n",
    "\n",
    "After the data is extracted, it’s loaded into a data storage system in the load phase. This system can be a database, a data warehouse, or a data lake.\n",
    "The data is loaded as-is, without any transformation. This means that the data maintains its original format and structure, which can be beneficial for preserving the data’s original context and meaning.\n",
    "\n",
    "#### Transform\n",
    "\n",
    "During this phase, the data is prepared for analysis. This preparation can involve various operations such as cleaning, filtering, aggregating, and summarizing the data. The goal of the transformation is to convert the raw data into a format that’s easy to analyze and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384671c-5dea-40e4-9fd0-e0deba3b8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "\n",
    "# For data extraction and transformation.\n",
    "import pandas as pd \n",
    "\n",
    "# Connecting to DB, Loading data to destination.\n",
    "import sqlalchemy as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07de8ba-9b05-4bc1-bbdb-f42513c4550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from: https://www.kaggle.com/datasets/shivamb/netflix-shows\n",
    "# Load the data using Pandas read_csv method.\n",
    "\n",
    "df = pd.read_csv('netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffdcd6-63aa-47f6-864c-46e377123033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to our destination DB like SQL Server, PostgreSQL, MySQL...\n",
    "\n",
    "engine = sql.create_engine('mssql://DB Connection Details')\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c7f7e-189a-462a-b527-6fca94cb7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to DB, if_exists = 'replace' will replace the existing data in table \"netflix_raw\"\n",
    "\n",
    "df.to_sql('netflix_raw', con=conn , index=False, if_exists = 'replace')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d85d70-0563-40bf-8be6-808ee4d39c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once data is loaded into DB, check if all data is loaded.\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370f6fa-1963-4629-b32c-00052f5d98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of rows loaded is same. \n",
    "# But we notice an issue with the TITLE column, that some of the title is present as \"?????\" in DB.\n",
    "\n",
    "\n",
    "df[df.show_id=='s5023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf6d0b-d068-4209-abe5-505c84e1904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that the Title contains a foreign language which is not properly displayed in DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8c7ac-2cbc-440c-8d8a-cc01b6d89ed1",
   "metadata": {},
   "source": [
    "### Issue\n",
    "\n",
    "By default, if_exists = 'replace' is using varchar(max) for all the rows.\n",
    "- To overcome this we will use nvarchar as data type for columns which has special characters.\n",
    "- We will check the length of the data in each column and use that to replace with varchar(max).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0024a-834e-4942-b707-4e71292367ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993da45-928e-43ee-90cd-a6e02d7ad31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are looping over each column to get the max length of the column. \n",
    "# We are using Try/Except to catch the columns with different datatype and cast it to str.\n",
    "\n",
    "\n",
    "for i in df.columns:\n",
    "    try: \n",
    "        print(max(df[i].dropna().str.len()))\n",
    "    except:\n",
    "        print(len(str(df[i])))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3456914-7a90-442c-b760-f9dcd40b0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use these lenght values to create a new table in DB using nvarchar(length)\n",
    "\n",
    "# Once the new table is created, load the data again using if_exists = 'append' \n",
    "\n",
    "engine = sql.create_engine('mssql://DB Connection Details')\n",
    "conn=engine.connect()\n",
    "df.to_sql('netflix__raw', con=conn , index=False, if_exists = 'append')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0528ec8-f37c-4fc5-881d-a4ab4b7a902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NULL values are there in each Columns\n",
    "\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e364a-a71b-4dbd-960f-42e7c63d2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e9782-9a74-49eb-9936-d619fb5f7d1e",
   "metadata": {},
   "source": [
    "Data Transformation and Cleaning is done using SQL. Refer to the SQL file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
